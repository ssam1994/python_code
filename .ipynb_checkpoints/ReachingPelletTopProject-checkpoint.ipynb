{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplabcut\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "task='ReachingPelletTop' # Enter the name of your experiment Task\n",
    "experimenter='Sarah' # Enter the name of the experimenter\n",
    "\n",
    "ddrive = \"D:%s\" % os.sep\n",
    "dlcFolder = os.path.join(ddrive, 'DeepLabCut')\n",
    "examplesFolder = os.path.join(dlcFolder, 'examples')\n",
    "workingDir = os.path.join(dlcFolder, 'projects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20200124_WT0_P1_C1_top.avi', '20200124_WT0_P2_C2_1_top.avi', '20200124_WT0_P2_C2_2_top.avi', '20200124_WT0_P3_L2_top.avi', '20200124_WT0_P5_L2_top.avi']\n"
     ]
    }
   ],
   "source": [
    "rawviddir = os.path.join(ddrive, 'reachingvideos', 'pellet', 'top')\n",
    "files = os.listdir(rawviddir)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = [os.path.join(rawviddir, f) for f in files]\n",
    "#path_config_file=deeplabcut.create_new_project(task,experimenter,video, working_directory=workingDir,copy_videos=False)\n",
    "path_config_file = os.path.join(workingDir, 'ReachingPelletTop-Sarah-2020-02-25', 'config.yaml') # Enter the path of the config file that was just created from the above step (check the folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory\n",
      "Starting %  . ['D:\\\\DeepLabCut\\\\projects\\\\ReachingTop-Sarah-2020-02-24\\\\videos']\n",
      "Loading  20200221_WT1_D2_top.avi and data.\n",
      "False 0 1280 0 1024\n",
      "500\n",
      "Duration of video [s]:  8.33 , recorded with  60.0 fps!\n",
      "Overall # of frames:  500 with cropped frame dimensions:  1280 1024\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 500/500 [00:06<00:00, 75.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  . ['D:\\\\DeepLabCut\\\\projects\\\\ReachingTop-Sarah-2020-02-24\\\\videos']\n",
      "Loading  20200221_WT1_D1_top.avi and data.\n",
      "False 0 1280 0 1024\n",
      "341\n",
      "Duration of video [s]:  5.68 , recorded with  60.0 fps!\n",
      "Overall # of frames:  341 with cropped frame dimensions:  1280 1024\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 341/341 [00:04<00:00, 75.79it/s]\n"
     ]
    }
   ],
   "source": [
    "videofile_path = os.path.join(workingDir, 'ReachingPelletTop-Sarah-2020-02-25', 'videos')\n",
    "deeplabcut.create_labeled_video(path_config_file,[videofile_path], draw_skeleton=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg=deeplabcut.auxiliaryfunctions.read_config(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg['bodyparts']=['leftEar','rightEar', 'leftEye', 'rightEye', 'nose', 'leftWrist', 'rightWrist', 'pellet']\n",
    "cfg['numframes2pick']=20\n",
    "deeplabcut.auxiliaryfunctions.write_config(path_config_file,cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\DeepLabCut\\projects\\ReachingPelletTop-Sarah-2020-02-25\\training-datasets\\iteration-0\\UnaugmentedDataSet_ReachingPelletTopFeb25  already exists!\n",
      "D:\\DeepLabCut\\projects\\ReachingPelletTop-Sarah-2020-02-25\\labeled-data\\20200124_WT0_P2_C2_1_top/CollectedData_Sarah.h5  not found (perhaps not annotated)\n",
      "D:\\DeepLabCut\\projects\\ReachingPelletTop-Sarah-2020-02-25\\labeled-data\\20200124_WT0_P2_C2_2_top/CollectedData_Sarah.h5  not found (perhaps not annotated)\n",
      "D:\\DeepLabCut\\projects\\ReachingPelletTop-Sarah-2020-02-25\\dlc-models\\iteration-0\\ReachingPelletTopFeb25-trainset95shuffle1  already exists!\n",
      "D:\\DeepLabCut\\projects\\ReachingPelletTop-Sarah-2020-02-25\\dlc-models\\iteration-0\\ReachingPelletTopFeb25-trainset95shuffle1//train  already exists!\n",
      "D:\\DeepLabCut\\projects\\ReachingPelletTop-Sarah-2020-02-25\\dlc-models\\iteration-0\\ReachingPelletTopFeb25-trainset95shuffle1//test  already exists!\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(path_config_file)\n",
    "posefile=os.path.join(cfg['project_path'],'dlc-models' + os.sep +'iteration-'+str(cfg['iteration'])+os.sep+ cfg['Task'] + cfg['date'] + '-trainset' + str(int(cfg['TrainingFraction'][0] * 100)) + 'shuffle' + str(1),'train' + os.sep + 'pose_cfg.yaml')\n",
    "DLC_config=deeplabcut.auxiliaryfunctions.read_plainconfig(posefile)\n",
    "DLC_config['save_iters']=100\n",
    "DLC_config['display_iters']=100\n",
    "deeplabcut.auxiliaryfunctions.write_plainconfig(posefile,DLC_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7]],\n",
      " 'all_joints_names': ['leftEar',\n",
      "                      'rightEar',\n",
      "                      'leftEye',\n",
      "                      'rightEye',\n",
      "                      'nose',\n",
      "                      'leftWrist',\n",
      "                      'rightWrist',\n",
      "                      'pellet'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ReachingPelletTopFeb25\\\\ReachingPelletTop_Sarah95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deterministic': False,\n",
      " 'display_iters': 100,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'D:\\\\anaconda\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ReachingPelletTopFeb25\\\\Documentation_data-ReachingPelletTop_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 8,\n",
      " 'optimizer': 'sgd',\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'D:\\\\DeepLabCut\\\\projects\\\\ReachingPelletTop-Sarah-2020-02-25',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 100,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'D:\\\\DeepLabCut\\\\projects\\\\ReachingPelletTop-Sarah-2020-02-25\\\\dlc-models\\\\iteration-0\\\\ReachingPelletTopFeb25-trainset95shuffle1\\\\train\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with standard pose-dataset loader.\n",
      "WARNING:tensorflow:From D:\\anaconda\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From D:\\anaconda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\nnet\\losses.py:38: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From D:\\anaconda\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from D:\\anaconda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'weigh_only_present_joints': False, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'D:\\\\DeepLabCut\\\\projects\\\\ReachingPelletTop-Sarah-2020-02-25\\\\dlc-models\\\\iteration-0\\\\ReachingPelletTopFeb25-trainset95shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'mirror': False, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'default', 'deterministic': False, 'crop': True, 'cropratio': 0.4, 'minsize': 100, 'leftwidth': 400, 'rightwidth': 400, 'topheight': 400, 'bottomheight': 400, 'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7]], 'all_joints_names': ['leftEar', 'rightEar', 'leftEye', 'rightEye', 'nose', 'leftWrist', 'rightWrist', 'pellet'], 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ReachingPelletTopFeb25\\\\ReachingPelletTop_Sarah95shuffle1.mat', 'display_iters': 100, 'init_weights': 'D:\\\\anaconda\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt', 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ReachingPelletTopFeb25\\\\Documentation_data-ReachingPelletTop_95shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 8, 'pos_dist_thresh': 17, 'project_path': 'D:\\\\DeepLabCut\\\\projects\\\\ReachingPelletTop-Sarah-2020-02-25', 'save_iters': 100, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 100 loss: 0.0653 lr: 0.005\n",
      "iteration: 200 loss: 0.0234 lr: 0.005\n",
      "iteration: 300 loss: 0.0214 lr: 0.005\n",
      "iteration: 400 loss: 0.0211 lr: 0.005\n",
      "iteration: 500 loss: 0.0205 lr: 0.005\n",
      "iteration: 600 loss: 0.0188 lr: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 700 loss: 0.0183 lr: 0.005\n",
      "iteration: 800 loss: 0.0174 lr: 0.005\n",
      "iteration: 900 loss: 0.0164 lr: 0.005\n",
      "iteration: 1000 loss: 0.0163 lr: 0.005\n",
      "iteration: 1100 loss: 0.0155 lr: 0.005\n",
      "iteration: 1200 loss: 0.0132 lr: 0.005\n",
      "iteration: 1300 loss: 0.0139 lr: 0.005\n",
      "iteration: 1400 loss: 0.0132 lr: 0.005\n",
      "iteration: 1500 loss: 0.0125 lr: 0.005\n",
      "iteration: 1600 loss: 0.0118 lr: 0.005\n",
      "iteration: 1700 loss: 0.0124 lr: 0.005\n",
      "iteration: 1800 loss: 0.0122 lr: 0.005\n",
      "iteration: 1900 loss: 0.0120 lr: 0.005\n",
      "iteration: 2000 loss: 0.0106 lr: 0.005\n",
      "iteration: 2100 loss: 0.0113 lr: 0.005\n",
      "iteration: 2200 loss: 0.0111 lr: 0.005\n",
      "iteration: 2300 loss: 0.0108 lr: 0.005\n",
      "iteration: 2400 loss: 0.0106 lr: 0.005\n",
      "iteration: 2500 loss: 0.0106 lr: 0.005\n",
      "iteration: 2600 loss: 0.0100 lr: 0.005\n",
      "iteration: 2700 loss: 0.0098 lr: 0.005\n",
      "iteration: 2800 loss: 0.0088 lr: 0.005\n",
      "iteration: 2900 loss: 0.0100 lr: 0.005\n",
      "iteration: 3000 loss: 0.0092 lr: 0.005\n",
      "iteration: 3100 loss: 0.0092 lr: 0.005\n",
      "iteration: 3200 loss: 0.0093 lr: 0.005\n",
      "iteration: 3300 loss: 0.0087 lr: 0.005\n",
      "iteration: 3400 loss: 0.0088 lr: 0.005\n",
      "iteration: 3500 loss: 0.0091 lr: 0.005\n",
      "iteration: 3600 loss: 0.0089 lr: 0.005\n",
      "iteration: 3700 loss: 0.0086 lr: 0.005\n",
      "iteration: 3800 loss: 0.0077 lr: 0.005\n",
      "iteration: 3900 loss: 0.0078 lr: 0.005\n",
      "iteration: 4000 loss: 0.0075 lr: 0.005\n",
      "iteration: 4100 loss: 0.0080 lr: 0.005\n",
      "iteration: 4200 loss: 0.0077 lr: 0.005\n",
      "iteration: 4300 loss: 0.0080 lr: 0.005\n",
      "iteration: 4400 loss: 0.0070 lr: 0.005\n",
      "iteration: 4500 loss: 0.0074 lr: 0.005\n",
      "iteration: 4600 loss: 0.0070 lr: 0.005\n",
      "iteration: 4700 loss: 0.0067 lr: 0.005\n",
      "iteration: 4800 loss: 0.0079 lr: 0.005\n",
      "iteration: 4900 loss: 0.0072 lr: 0.005\n",
      "iteration: 5000 loss: 0.0078 lr: 0.005\n",
      "iteration: 5100 loss: 0.0076 lr: 0.005\n",
      "iteration: 5200 loss: 0.0071 lr: 0.005\n",
      "iteration: 5300 loss: 0.0066 lr: 0.005\n",
      "iteration: 5400 loss: 0.0071 lr: 0.005\n",
      "iteration: 5500 loss: 0.0078 lr: 0.005\n",
      "iteration: 5600 loss: 0.0070 lr: 0.005\n",
      "iteration: 5700 loss: 0.0064 lr: 0.005\n",
      "iteration: 5800 loss: 0.0067 lr: 0.005\n",
      "iteration: 5900 loss: 0.0066 lr: 0.005\n",
      "iteration: 6000 loss: 0.0062 lr: 0.005\n",
      "iteration: 6100 loss: 0.0056 lr: 0.005\n",
      "iteration: 6200 loss: 0.0066 lr: 0.005\n",
      "iteration: 6300 loss: 0.0064 lr: 0.005\n",
      "iteration: 6400 loss: 0.0060 lr: 0.005\n",
      "iteration: 6500 loss: 0.0063 lr: 0.005\n",
      "iteration: 6600 loss: 0.0056 lr: 0.005\n",
      "iteration: 6700 loss: 0.0058 lr: 0.005\n",
      "iteration: 6800 loss: 0.0058 lr: 0.005\n",
      "iteration: 6900 loss: 0.0061 lr: 0.005\n",
      "iteration: 7000 loss: 0.0059 lr: 0.005\n",
      "iteration: 7100 loss: 0.0059 lr: 0.005\n",
      "iteration: 7200 loss: 0.0056 lr: 0.005\n",
      "iteration: 7300 loss: 0.0056 lr: 0.005\n",
      "iteration: 7400 loss: 0.0060 lr: 0.005\n",
      "iteration: 7500 loss: 0.0055 lr: 0.005\n",
      "iteration: 7600 loss: 0.0056 lr: 0.005\n",
      "iteration: 7700 loss: 0.0057 lr: 0.005\n",
      "iteration: 7800 loss: 0.0054 lr: 0.005\n",
      "iteration: 7900 loss: 0.0054 lr: 0.005\n",
      "iteration: 8000 loss: 0.0057 lr: 0.005\n",
      "iteration: 8100 loss: 0.0057 lr: 0.005\n",
      "iteration: 8200 loss: 0.0052 lr: 0.005\n",
      "iteration: 8300 loss: 0.0053 lr: 0.005\n",
      "iteration: 8400 loss: 0.0049 lr: 0.005\n",
      "iteration: 8500 loss: 0.0052 lr: 0.005\n",
      "iteration: 8600 loss: 0.0050 lr: 0.005\n",
      "iteration: 8700 loss: 0.0052 lr: 0.005\n",
      "iteration: 8800 loss: 0.0050 lr: 0.005\n",
      "iteration: 8900 loss: 0.0056 lr: 0.005\n",
      "iteration: 9000 loss: 0.0052 lr: 0.005\n",
      "iteration: 9100 loss: 0.0047 lr: 0.005\n",
      "iteration: 9200 loss: 0.0053 lr: 0.005\n",
      "iteration: 9300 loss: 0.0050 lr: 0.005\n",
      "iteration: 9400 loss: 0.0051 lr: 0.005\n",
      "iteration: 9500 loss: 0.0046 lr: 0.005\n",
      "iteration: 9600 loss: 0.0050 lr: 0.005\n",
      "iteration: 9700 loss: 0.0048 lr: 0.005\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(path_config_file, gputouse=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "New video was added to the project! Use the function 'extract_frames' to select frames for labeling.\n"
     ]
    }
   ],
   "source": [
    "#newVids = [os.path.join(ddrive, 'academy_videos', 'f-cam', 'M22_HoldBite_1561429194_FrontVideo.avi')]\n",
    "deeplabcut.add_new_videos(path_config_file, newVids)\n",
    "#deeplabcut.add_new_videos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file read successfully.\n",
      "Do you want to extract (perhaps additional) frames for video: D:\\reachingvideos\\pellet\\top\\20200124_WT0_P1_C1_top.avi ?\n",
      "yes/noyes\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 3.18  seconds.\n",
      "Extracting and downsampling... 191  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "191it [00:00, 212.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Do you want to extract (perhaps additional) frames for video: D:\\reachingvideos\\pellet\\top\\20200124_WT0_P2_C2_1_top.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: D:\\reachingvideos\\pellet\\top\\20200124_WT0_P2_C2_2_top.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: D:\\reachingvideos\\pellet\\top\\20200124_WT0_P3_L2_top.avi ?\n",
      "yes/noyes\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 9.53  seconds.\n",
      "Extracting and downsampling... 572  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "572it [00:02, 210.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Do you want to extract (perhaps additional) frames for video: D:\\reachingvideos\\pellet\\top\\20200124_WT0_P5_L2_top.avi ?\n",
      "yes/noyes\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 14.5  seconds.\n",
      "Extracting and downsampling... 870  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "870it [00:04, 212.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "\n",
      "Frames were selected.\n",
      "You can now label the frames using the function 'label_frames' (if you extracted enough frames for all videos).\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "#there are other ways to grab frames, such as uniformly; please see the paper:\n",
    "\n",
    "#AUTOMATIC:\n",
    "deeplabcut.extract_frames(path_config_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can now check the labels, using 'check_labels' before proceeding. Then, you can use the function 'create_training_dataset' to create the training dataset.\n"
     ]
    }
   ],
   "source": [
    "%gui wx\n",
    "deeplabcut.label_frames(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by Sarah.\n",
      "They are stored in the following folder: D:\\DeepLabCut\\projects\\ReachingPelletTop-Sarah-2020-02-25\\labeled-data\\20200124_WT0_P1_C1_top_labeled.\n",
      "Attention: D:\\DeepLabCut\\projects\\ReachingPelletTop-Sarah-2020-02-25\\labeled-data\\20200124_WT0_P2_C2_1_top does not appear to have labeled data!\n",
      "Attention: D:\\DeepLabCut\\projects\\ReachingPelletTop-Sarah-2020-02-25\\labeled-data\\20200124_WT0_P2_C2_2_top does not appear to have labeled data!\n",
      "They are stored in the following folder: D:\\DeepLabCut\\projects\\ReachingPelletTop-Sarah-2020-02-25\\labeled-data\\20200124_WT0_P3_L2_top_labeled.\n",
      "They are stored in the following folder: D:\\DeepLabCut\\projects\\ReachingPelletTop-Sarah-2020-02-25\\labeled-data\\20200124_WT0_P5_L2_top_labeled.\n",
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.check_labels(path_config_file) #this creates a subdirectory with the frames + your labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\DeepLabCut\\projects\\HoldBiteFront-Sarah-2019-08-28\\training-datasets\\iteration-0\\UnaugmentedDataSet_HoldBiteFrontAug28  already exists!\n",
      "D:\\DeepLabCut\\projects\\HoldBiteFront-Sarah-2019-08-28\\labeled-data\\M20_HoldBite_1561092244_FrontVideo/CollectedData_Sarah.h5  not found (perhaps not annotated)\n",
      "D:\\DeepLabCut\\projects\\HoldBiteFront-Sarah-2019-08-28\\labeled-data\\M20_HoldBite_1561089546_FrontVideo/CollectedData_Sarah.h5  not found (perhaps not annotated)\n",
      "D:\\DeepLabCut\\projects\\HoldBiteFront-Sarah-2019-08-28\\labeled-data\\M20_HoldBite_1561085754_FrontVideo/CollectedData_Sarah.h5  not found (perhaps not annotated)\n",
      "D:\\DeepLabCut\\projects\\HoldBiteFront-Sarah-2019-08-28\\dlc-models\\iteration-0\\HoldBiteFrontAug28-trainset95shuffle1  already exists!\n",
      "D:\\DeepLabCut\\projects\\HoldBiteFront-Sarah-2019-08-28\\dlc-models\\iteration-0\\HoldBiteFrontAug28-trainset95shuffle1//train  already exists!\n",
      "D:\\DeepLabCut\\projects\\HoldBiteFront-Sarah-2019-08-28\\dlc-models\\iteration-0\\HoldBiteFrontAug28-trainset95shuffle1//test  already exists!\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\DeepLabCut\\\\projects\\\\HoldBiteFront-Sarah-2019-08-28\\\\dlc-models\\\\iteration-0\\\\HoldBiteFrontAug28-trainset95shuffle1\\\\train\\\\pose_cfg.yaml'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7]],\n",
      " 'all_joints_names': ['leftEar',\n",
      "                      'rightEar',\n",
      "                      'leftEye',\n",
      "                      'rightEye',\n",
      "                      'nose',\n",
      "                      'leftWrist',\n",
      "                      'rightWrist',\n",
      "                      'waterDrop'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ReachingTopFeb24\\\\ReachingTop_Sarah95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deterministic': False,\n",
      " 'display_iters': 100,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'D:\\\\anaconda\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ReachingTopFeb24\\\\Documentation_data-ReachingTop_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 8,\n",
      " 'optimizer': 'sgd',\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'D:\\\\DeepLabCut\\\\projects\\\\ReachingTop-Sarah-2020-02-24',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 100,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'D:\\\\DeepLabCut\\\\projects\\\\ReachingTop-Sarah-2020-02-24\\\\dlc-models\\\\iteration-0\\\\ReachingTopFeb24-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running  DeepCut_resnet50_ReachingTopFeb24shuffle1_14900  with # of trainingiterations: 14900\n",
      "INFO:tensorflow:Restoring parameters from D:\\DeepLabCut\\projects\\ReachingTop-Sarah-2020-02-24\\dlc-models\\iteration-0\\ReachingTopFeb24-trainset95shuffle1\\train\\snapshot-14900\n",
      "Analyzing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [00:16,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done and results stored for snapshot:  snapshot-14900\n",
      "Results for 14900  training iterations: 95 1 train error: 6.93 pixels. Test error: 6.5  pixels.\n",
      "With pcutoff of 0.1  train error: 6.93 pixels. Test error: 6.5 pixels\n",
      "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
      "Plotting...\n",
      "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
      "If it generalizes well, choose the best model for prediction and update the config file with the appropriate index for the 'snapshotindex'.\n",
      "Use the function 'analyze_video' to make predictions on new videos.\n",
      "Otherwise consider retraining the network (see DeepLabCut workflow Fig 2)\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.evaluate_network(path_config_file, plotting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7]],\n",
      " 'all_joints_names': ['leftEar',\n",
      "                      'rightEar',\n",
      "                      'leftEye',\n",
      "                      'rightEye',\n",
      "                      'nose',\n",
      "                      'leftWrist',\n",
      "                      'rightWrist',\n",
      "                      'waterDrop'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ReachingTopFeb24\\\\ReachingTop_Sarah95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deterministic': False,\n",
      " 'display_iters': 100,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'D:\\\\anaconda\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ReachingTopFeb24\\\\Documentation_data-ReachingTop_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 8,\n",
      " 'optimizer': 'sgd',\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'D:\\\\DeepLabCut\\\\projects\\\\ReachingTop-Sarah-2020-02-24',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 100,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'D:\\\\DeepLabCut\\\\projects\\\\ReachingTop-Sarah-2020-02-24\\\\dlc-models\\\\iteration-0\\\\ReachingTopFeb24-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-14900 for model D:\\DeepLabCut\\projects\\ReachingTop-Sarah-2020-02-24\\dlc-models\\iteration-0\\ReachingTopFeb24-trainset95shuffle1\n",
      "num_outputs =  1\n",
      "INFO:tensorflow:Restoring parameters from D:\\DeepLabCut\\projects\\ReachingTop-Sarah-2020-02-24\\dlc-models\\iteration-0\\ReachingTopFeb24-trainset95shuffle1\\train\\snapshot-14900\n",
      "Analyzing all the videos in the directory\n",
      "Starting to analyze %  20200221_WT1_D1_top.avi\n",
      "Loading  20200221_WT1_D1_top.avi\n",
      "Duration of video [s]:  5.68 , recorded with  60.0 fps!\n",
      "Overall # of frames:  341  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "350it [01:14,  5.08it/s]                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "350it [01:16,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in ....\n",
      "Saving csv poses!\n",
      "Starting to analyze %  20200221_WT1_D2_top.avi\n",
      "Loading  20200221_WT1_D2_top.avi\n",
      "Duration of video [s]:  8.33 , recorded with  60.0 fps!\n",
      "Overall # of frames:  500  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "510it [01:42,  5.07it/s]                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "510it [01:43,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in ....\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract any outlier frames!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DeepCut_resnet50_ReachingTopFeb24shuffle1_14900'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videofile_path = [os.path.join(ddrive, 'DeepLabCut', 'projects', 'ReachingTop-Sarah-2020-02-24', 'videos')]\n",
    "deeplabcut.analyze_videos(path_config_file,videofile_path, videotype='.avi', save_as_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isfile(os.sep.join(['D:', 'academy_videos', 'f-cam', 'M18_HoldBite_1561436695_FrontVideo.avi']))\n",
    "#os.path.isfile(\"D:\\academy_videos\\f-cam\\M18_HoldBite_1561436695_FrontVideo.avi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
