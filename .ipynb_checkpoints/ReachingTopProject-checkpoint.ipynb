{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplabcut\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "task='ReachingTop' # Enter the name of your experiment Task\n",
    "experimenter='Sarah' # Enter the name of the experimenter\n",
    "\n",
    "ddrive = \"D:%s\" % os.sep\n",
    "dlcFolder = os.path.join(ddrive, 'DeepLabCut')\n",
    "examplesFolder = os.path.join(dlcFolder, 'examples')\n",
    "workingDir = os.path.join(dlcFolder, 'projects')\n",
    "rawviddir = os.path.join(ddrive, 'reachingvideos', 'waterdrop', 'top')\n",
    "files = os.listdir(rawviddir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = [os.path.join(rawviddir, f) for f in files]\n",
    "#path_config_file=deeplabcut.create_new_project(task,experimenter,video, working_directory=workingDir,copy_videos=False)\n",
    "path_config_file = os.path.join(workingDir, 'ReachingTop-Sarah-2020-02-24', 'config.yaml') # Enter the path of the config file that was just created from the above step (check the folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the symbolic link of the video\n",
      "Creating the symbolic link of the video\n",
      "New video was added to the project! Use the function 'extract_frames' to select frames for labeling.\n"
     ]
    }
   ],
   "source": [
    "#newVids = [os.path.join(ddrive, 'academy_videos', 'f-cam', 'M22_HoldBite_1561429194_FrontVideo.avi')]\n",
    "deeplabcut.add_new_videos(path_config_file, video)\n",
    "#deeplabcut.add_new_videos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory\n",
      "Starting %  . ['D:\\\\DeepLabCut\\\\projects\\\\ReachingTop-Sarah-2020-02-24\\\\videos']\n",
      "Loading  20200221_WT1_D2_top.avi and data.\n",
      "False 0 1280 0 1024\n",
      "500\n",
      "Duration of video [s]:  8.33 , recorded with  60.0 fps!\n",
      "Overall # of frames:  500 with cropped frame dimensions:  1280 1024\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 500/500 [00:06<00:00, 75.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  . ['D:\\\\DeepLabCut\\\\projects\\\\ReachingTop-Sarah-2020-02-24\\\\videos']\n",
      "Loading  20200221_WT1_D1_top.avi and data.\n",
      "False 0 1280 0 1024\n",
      "341\n",
      "Duration of video [s]:  5.68 , recorded with  60.0 fps!\n",
      "Overall # of frames:  341 with cropped frame dimensions:  1280 1024\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 341/341 [00:04<00:00, 75.79it/s]\n"
     ]
    }
   ],
   "source": [
    "videofile_path = os.path.join(workingDir, 'ReachingTop-Sarah-2020-02-24', 'videos')\n",
    "deeplabcut.create_labeled_video(path_config_file,[videofile_path], draw_skeleton=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg=deeplabcut.auxiliaryfunctions.read_config(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg['bodyparts']=['leftEar','rightEar', 'leftEye', 'rightEye', 'nose', 'leftWrist', 'rightWrist', 'waterDrop']\n",
    "cfg['numframes2pick']=60\n",
    "deeplabcut.auxiliaryfunctions.write_config(path_config_file,cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\DeepLabCut\\projects\\ReachingTop-Sarah-2020-02-24\\training-datasets\\iteration-0\\UnaugmentedDataSet_ReachingTopFeb24  already exists!\n",
      "D:\\DeepLabCut\\projects\\ReachingTop-Sarah-2020-02-24\\labeled-data\\20200221_WT1_D2_top/CollectedData_Sarah.h5  not found (perhaps not annotated)\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(path_config_file)\n",
    "posefile=os.path.join(cfg['project_path'],'dlc-models' + os.sep +'iteration-'+str(cfg['iteration'])+os.sep+ cfg['Task'] + cfg['date'] + '-trainset' + str(int(cfg['TrainingFraction'][0] * 100)) + 'shuffle' + str(1),'train' + os.sep + 'pose_cfg.yaml')\n",
    "DLC_config=deeplabcut.auxiliaryfunctions.read_plainconfig(posefile)\n",
    "DLC_config['save_iters']=100\n",
    "DLC_config['display_iters']=100\n",
    "deeplabcut.auxiliaryfunctions.write_plainconfig(posefile,DLC_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7]],\n",
      " 'all_joints_names': ['leftEar',\n",
      "                      'rightEar',\n",
      "                      'leftEye',\n",
      "                      'rightEye',\n",
      "                      'nose',\n",
      "                      'leftWrist',\n",
      "                      'rightWrist',\n",
      "                      'waterDrop'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ReachingTopFeb24\\\\ReachingTop_Sarah95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deterministic': False,\n",
      " 'display_iters': 100,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'D:\\\\anaconda\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ReachingTopFeb24\\\\Documentation_data-ReachingTop_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 8,\n",
      " 'optimizer': 'sgd',\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'D:\\\\DeepLabCut\\\\projects\\\\ReachingTop-Sarah-2020-02-24',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 100,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'D:\\\\DeepLabCut\\\\projects\\\\ReachingTop-Sarah-2020-02-24\\\\dlc-models\\\\iteration-0\\\\ReachingTopFeb24-trainset95shuffle1\\\\train\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with standard pose-dataset loader.\n",
      "WARNING:tensorflow:From D:\\anaconda\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From D:\\anaconda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\nnet\\losses.py:38: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From D:\\anaconda\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from D:\\anaconda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'weigh_only_present_joints': False, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'D:\\\\DeepLabCut\\\\projects\\\\ReachingTop-Sarah-2020-02-24\\\\dlc-models\\\\iteration-0\\\\ReachingTopFeb24-trainset95shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'mirror': False, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'default', 'deterministic': False, 'crop': True, 'cropratio': 0.4, 'minsize': 100, 'leftwidth': 400, 'rightwidth': 400, 'topheight': 400, 'bottomheight': 400, 'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7]], 'all_joints_names': ['leftEar', 'rightEar', 'leftEye', 'rightEye', 'nose', 'leftWrist', 'rightWrist', 'waterDrop'], 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ReachingTopFeb24\\\\ReachingTop_Sarah95shuffle1.mat', 'display_iters': 100, 'init_weights': 'D:\\\\anaconda\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt', 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ReachingTopFeb24\\\\Documentation_data-ReachingTop_95shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 8, 'pos_dist_thresh': 17, 'project_path': 'D:\\\\DeepLabCut\\\\projects\\\\ReachingTop-Sarah-2020-02-24', 'save_iters': 100, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 100 loss: 0.0625 lr: 0.005\n",
      "iteration: 200 loss: 0.0225 lr: 0.005\n",
      "iteration: 300 loss: 0.0221 lr: 0.005\n",
      "iteration: 400 loss: 0.0201 lr: 0.005\n",
      "iteration: 500 loss: 0.0197 lr: 0.005\n",
      "iteration: 600 loss: 0.0188 lr: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 700 loss: 0.0170 lr: 0.005\n",
      "iteration: 800 loss: 0.0153 lr: 0.005\n",
      "iteration: 900 loss: 0.0163 lr: 0.005\n",
      "iteration: 1000 loss: 0.0139 lr: 0.005\n",
      "iteration: 1100 loss: 0.0144 lr: 0.005\n",
      "iteration: 1200 loss: 0.0134 lr: 0.005\n",
      "iteration: 1300 loss: 0.0138 lr: 0.005\n",
      "iteration: 1400 loss: 0.0126 lr: 0.005\n",
      "iteration: 1500 loss: 0.0134 lr: 0.005\n",
      "iteration: 1600 loss: 0.0115 lr: 0.005\n",
      "iteration: 1700 loss: 0.0113 lr: 0.005\n",
      "iteration: 1800 loss: 0.0106 lr: 0.005\n",
      "iteration: 1900 loss: 0.0109 lr: 0.005\n",
      "iteration: 2000 loss: 0.0105 lr: 0.005\n",
      "iteration: 2100 loss: 0.0096 lr: 0.005\n",
      "iteration: 2200 loss: 0.0097 lr: 0.005\n",
      "iteration: 2300 loss: 0.0095 lr: 0.005\n",
      "iteration: 2400 loss: 0.0099 lr: 0.005\n",
      "iteration: 2500 loss: 0.0089 lr: 0.005\n",
      "iteration: 2600 loss: 0.0087 lr: 0.005\n",
      "iteration: 2700 loss: 0.0086 lr: 0.005\n",
      "iteration: 2800 loss: 0.0096 lr: 0.005\n",
      "iteration: 2900 loss: 0.0085 lr: 0.005\n",
      "iteration: 3000 loss: 0.0092 lr: 0.005\n",
      "iteration: 3100 loss: 0.0079 lr: 0.005\n",
      "iteration: 3200 loss: 0.0086 lr: 0.005\n",
      "iteration: 3300 loss: 0.0084 lr: 0.005\n",
      "iteration: 3400 loss: 0.0080 lr: 0.005\n",
      "iteration: 3500 loss: 0.0071 lr: 0.005\n",
      "iteration: 3600 loss: 0.0076 lr: 0.005\n",
      "iteration: 3700 loss: 0.0083 lr: 0.005\n",
      "iteration: 3800 loss: 0.0078 lr: 0.005\n",
      "iteration: 3900 loss: 0.0079 lr: 0.005\n",
      "iteration: 4000 loss: 0.0076 lr: 0.005\n",
      "iteration: 4100 loss: 0.0072 lr: 0.005\n",
      "iteration: 4200 loss: 0.0073 lr: 0.005\n",
      "iteration: 4300 loss: 0.0074 lr: 0.005\n",
      "iteration: 4400 loss: 0.0070 lr: 0.005\n",
      "iteration: 4500 loss: 0.0072 lr: 0.005\n",
      "iteration: 4600 loss: 0.0066 lr: 0.005\n",
      "iteration: 4700 loss: 0.0067 lr: 0.005\n",
      "iteration: 4800 loss: 0.0068 lr: 0.005\n",
      "iteration: 4900 loss: 0.0070 lr: 0.005\n",
      "iteration: 5000 loss: 0.0070 lr: 0.005\n",
      "iteration: 5100 loss: 0.0062 lr: 0.005\n",
      "iteration: 5200 loss: 0.0065 lr: 0.005\n",
      "iteration: 5300 loss: 0.0067 lr: 0.005\n",
      "iteration: 5400 loss: 0.0068 lr: 0.005\n",
      "iteration: 5500 loss: 0.0065 lr: 0.005\n",
      "iteration: 5600 loss: 0.0065 lr: 0.005\n",
      "iteration: 5700 loss: 0.0066 lr: 0.005\n",
      "iteration: 5800 loss: 0.0061 lr: 0.005\n",
      "iteration: 5900 loss: 0.0067 lr: 0.005\n",
      "iteration: 6000 loss: 0.0065 lr: 0.005\n",
      "iteration: 6100 loss: 0.0065 lr: 0.005\n",
      "iteration: 6200 loss: 0.0065 lr: 0.005\n",
      "iteration: 6300 loss: 0.0068 lr: 0.005\n",
      "iteration: 6400 loss: 0.0060 lr: 0.005\n",
      "iteration: 6500 loss: 0.0062 lr: 0.005\n",
      "iteration: 6600 loss: 0.0060 lr: 0.005\n",
      "iteration: 6700 loss: 0.0056 lr: 0.005\n",
      "iteration: 6800 loss: 0.0059 lr: 0.005\n",
      "iteration: 6900 loss: 0.0056 lr: 0.005\n",
      "iteration: 7000 loss: 0.0059 lr: 0.005\n",
      "iteration: 7100 loss: 0.0051 lr: 0.005\n",
      "iteration: 7200 loss: 0.0058 lr: 0.005\n",
      "iteration: 7300 loss: 0.0059 lr: 0.005\n",
      "iteration: 7400 loss: 0.0061 lr: 0.005\n",
      "iteration: 7500 loss: 0.0060 lr: 0.005\n",
      "iteration: 7600 loss: 0.0053 lr: 0.005\n",
      "iteration: 7700 loss: 0.0053 lr: 0.005\n",
      "iteration: 7800 loss: 0.0053 lr: 0.005\n",
      "iteration: 7900 loss: 0.0049 lr: 0.005\n",
      "iteration: 8000 loss: 0.0056 lr: 0.005\n",
      "iteration: 8100 loss: 0.0057 lr: 0.005\n",
      "iteration: 8200 loss: 0.0054 lr: 0.005\n",
      "iteration: 8300 loss: 0.0052 lr: 0.005\n",
      "iteration: 8400 loss: 0.0053 lr: 0.005\n",
      "iteration: 8500 loss: 0.0051 lr: 0.005\n",
      "iteration: 8600 loss: 0.0056 lr: 0.005\n",
      "iteration: 8700 loss: 0.0050 lr: 0.005\n",
      "iteration: 8800 loss: 0.0051 lr: 0.005\n",
      "iteration: 8900 loss: 0.0052 lr: 0.005\n",
      "iteration: 9000 loss: 0.0050 lr: 0.005\n",
      "iteration: 9100 loss: 0.0050 lr: 0.005\n",
      "iteration: 9200 loss: 0.0056 lr: 0.005\n",
      "iteration: 9300 loss: 0.0052 lr: 0.005\n",
      "iteration: 9400 loss: 0.0053 lr: 0.005\n",
      "iteration: 9500 loss: 0.0053 lr: 0.005\n",
      "iteration: 9600 loss: 0.0045 lr: 0.005\n",
      "iteration: 9700 loss: 0.0047 lr: 0.005\n",
      "iteration: 9800 loss: 0.0048 lr: 0.005\n",
      "iteration: 9900 loss: 0.0051 lr: 0.005\n",
      "iteration: 10000 loss: 0.0044 lr: 0.005\n",
      "iteration: 10100 loss: 0.0089 lr: 0.02\n",
      "iteration: 10200 loss: 0.0084 lr: 0.02\n",
      "iteration: 10300 loss: 0.0093 lr: 0.02\n",
      "iteration: 10400 loss: 0.0091 lr: 0.02\n",
      "iteration: 10500 loss: 0.0078 lr: 0.02\n",
      "iteration: 10600 loss: 0.0075 lr: 0.02\n",
      "iteration: 10700 loss: 0.0072 lr: 0.02\n",
      "iteration: 10800 loss: 0.0085 lr: 0.02\n",
      "iteration: 10900 loss: 0.0077 lr: 0.02\n",
      "iteration: 11000 loss: 0.0071 lr: 0.02\n",
      "iteration: 11100 loss: 0.0066 lr: 0.02\n",
      "iteration: 11200 loss: 0.0072 lr: 0.02\n",
      "iteration: 11300 loss: 0.0070 lr: 0.02\n",
      "iteration: 11400 loss: 0.0064 lr: 0.02\n",
      "iteration: 11500 loss: 0.0068 lr: 0.02\n",
      "iteration: 11600 loss: 0.0066 lr: 0.02\n",
      "iteration: 11700 loss: 0.0061 lr: 0.02\n",
      "iteration: 11800 loss: 0.0059 lr: 0.02\n",
      "iteration: 11900 loss: 0.0060 lr: 0.02\n",
      "iteration: 12000 loss: 0.0066 lr: 0.02\n",
      "iteration: 12100 loss: 0.0059 lr: 0.02\n",
      "iteration: 12200 loss: 0.0057 lr: 0.02\n",
      "iteration: 12300 loss: 0.0057 lr: 0.02\n",
      "iteration: 12400 loss: 0.0054 lr: 0.02\n",
      "iteration: 12500 loss: 0.0060 lr: 0.02\n",
      "iteration: 12600 loss: 0.0057 lr: 0.02\n",
      "iteration: 12700 loss: 0.0052 lr: 0.02\n",
      "iteration: 12800 loss: 0.0050 lr: 0.02\n",
      "iteration: 12900 loss: 0.0050 lr: 0.02\n",
      "iteration: 13000 loss: 0.0055 lr: 0.02\n",
      "iteration: 13100 loss: 0.0049 lr: 0.02\n",
      "iteration: 13200 loss: 0.0048 lr: 0.02\n",
      "iteration: 13300 loss: 0.0047 lr: 0.02\n",
      "iteration: 13400 loss: 0.0049 lr: 0.02\n",
      "iteration: 13500 loss: 0.0049 lr: 0.02\n",
      "iteration: 13600 loss: 0.0049 lr: 0.02\n",
      "iteration: 13700 loss: 0.0052 lr: 0.02\n",
      "iteration: 13800 loss: 0.0041 lr: 0.02\n",
      "iteration: 13900 loss: 0.0043 lr: 0.02\n",
      "iteration: 14000 loss: 0.0045 lr: 0.02\n",
      "iteration: 14100 loss: 0.0051 lr: 0.02\n",
      "iteration: 14200 loss: 0.0047 lr: 0.02\n",
      "iteration: 14300 loss: 0.0043 lr: 0.02\n",
      "iteration: 14400 loss: 0.0045 lr: 0.02\n",
      "iteration: 14500 loss: 0.0047 lr: 0.02\n",
      "iteration: 14600 loss: 0.0042 lr: 0.02\n",
      "iteration: 14700 loss: 0.0047 lr: 0.02\n",
      "iteration: 14800 loss: 0.0043 lr: 0.02\n",
      "iteration: 14900 loss: 0.0041 lr: 0.02\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-171fd1c55e61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdeeplabcut\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_config_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgputouse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(config, shuffle, trainingsetindex, gputouse, max_snapshots_to_keep, autotune, displayiters, saveiters, maxiters)\u001b[0m\n\u001b[0;32m     95\u001b[0m           \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposeconfigfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_to_keep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#pass on path and file name for pose_cfg.yaml!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m       \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m           \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(config, shuffle, trainingsetindex, gputouse, max_snapshots_to_keep, autotune, displayiters, saveiters, maxiters)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m           \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposeconfigfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_to_keep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#pass on path and file name for pose_cfg.yaml!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(config_yaml, displayiters, saveiters, maxiters, max_to_keep)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msave_iters\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mit\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mit\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mmodel_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnapshot_prefix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m             \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[0mlrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs, save_debug_info)\u001b[0m\n\u001b[0;32m   1198\u001b[0m               \u001b[0mmeta_graph_filename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1199\u001b[0m               \u001b[0mstrip_default_attrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrip_default_attrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1200\u001b[1;33m               save_debug_info=save_debug_info)\n\u001b[0m\u001b[0;32m   1201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_empty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mexport_meta_graph\u001b[1;34m(self, filename, collection_list, as_text, export_scope, clear_devices, clear_extraneous_savers, strip_default_attrs, save_debug_info)\u001b[0m\n\u001b[0;32m   1241\u001b[0m     return export_meta_graph(\n\u001b[0;32m   1242\u001b[0m         \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1243\u001b[1;33m         \u001b[0mgraph_def\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_graph_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madd_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1244\u001b[0m         \u001b[0msaver_def\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1245\u001b[0m         \u001b[0mcollection_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollection_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mas_graph_def\u001b[1;34m(self, from_version, add_shapes)\u001b[0m\n\u001b[0;32m   3463\u001b[0m     \"\"\"\n\u001b[0;32m   3464\u001b[0m     \u001b[1;31m# pylint: enable=line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3465\u001b[1;33m     \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_graph_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrom_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3466\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_def\u001b[1;34m(self, from_version, add_shapes)\u001b[0m\n\u001b[0;32m   3400\u001b[0m           \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nodes_by_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3401\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3402\u001b[1;33m             node.attr[\"_output_shapes\"].list.shape.extend(\n\u001b[0m\u001b[0;32m   3403\u001b[0m                 [output.get_shape().as_proto() for output in op.outputs])\n\u001b[0;32m   3404\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfunction_def\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(path_config_file, gputouse=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file read successfully.\n",
      "Do you want to extract (perhaps additional) frames for video: D:\\reachingvideos\\20200221_WT1_D1_top.avi ?\n",
      "yes/noyes\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 5.68  seconds.\n",
      "Extracting and downsampling... 341  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "341it [00:01, 186.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Do you want to extract (perhaps additional) frames for video: D:\\reachingvideos\\20200221_WT1_D2_top.avi ?\n",
      "yes/noyes\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 8.33  seconds.\n",
      "Extracting and downsampling... 500  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [00:02, 202.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "\n",
      "Frames were selected.\n",
      "You can now label the frames using the function 'label_frames' (if you extracted enough frames for all videos).\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "#there are other ways to grab frames, such as uniformly; please see the paper:\n",
    "\n",
    "#AUTOMATIC:\n",
    "deeplabcut.extract_frames(path_config_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can now check the labels, using 'check_labels' before proceeding. Then, you can use the function 'create_training_dataset' to create the training dataset.\n"
     ]
    }
   ],
   "source": [
    "%gui wx\n",
    "deeplabcut.label_frames(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by Sarah.\n",
      "They are stored in the following folder: D:\\DeepLabCut\\projects\\ReachingTop-Sarah-2020-02-24\\labeled-data\\20200221_WT1_D1_top_labeled.\n",
      "Attention: D:\\DeepLabCut\\projects\\ReachingTop-Sarah-2020-02-24\\labeled-data\\20200221_WT1_D2_top does not appear to have labeled data!\n",
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.check_labels(path_config_file) #this creates a subdirectory with the frames + your labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\DeepLabCut\\projects\\HoldBiteFront-Sarah-2019-08-28\\training-datasets\\iteration-0\\UnaugmentedDataSet_HoldBiteFrontAug28  already exists!\n",
      "D:\\DeepLabCut\\projects\\HoldBiteFront-Sarah-2019-08-28\\labeled-data\\M20_HoldBite_1561092244_FrontVideo/CollectedData_Sarah.h5  not found (perhaps not annotated)\n",
      "D:\\DeepLabCut\\projects\\HoldBiteFront-Sarah-2019-08-28\\labeled-data\\M20_HoldBite_1561089546_FrontVideo/CollectedData_Sarah.h5  not found (perhaps not annotated)\n",
      "D:\\DeepLabCut\\projects\\HoldBiteFront-Sarah-2019-08-28\\labeled-data\\M20_HoldBite_1561085754_FrontVideo/CollectedData_Sarah.h5  not found (perhaps not annotated)\n",
      "D:\\DeepLabCut\\projects\\HoldBiteFront-Sarah-2019-08-28\\dlc-models\\iteration-0\\HoldBiteFrontAug28-trainset95shuffle1  already exists!\n",
      "D:\\DeepLabCut\\projects\\HoldBiteFront-Sarah-2019-08-28\\dlc-models\\iteration-0\\HoldBiteFrontAug28-trainset95shuffle1//train  already exists!\n",
      "D:\\DeepLabCut\\projects\\HoldBiteFront-Sarah-2019-08-28\\dlc-models\\iteration-0\\HoldBiteFrontAug28-trainset95shuffle1//test  already exists!\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\DeepLabCut\\\\projects\\\\HoldBiteFront-Sarah-2019-08-28\\\\dlc-models\\\\iteration-0\\\\HoldBiteFrontAug28-trainset95shuffle1\\\\train\\\\pose_cfg.yaml'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7]],\n",
      " 'all_joints_names': ['leftEar',\n",
      "                      'rightEar',\n",
      "                      'leftEye',\n",
      "                      'rightEye',\n",
      "                      'nose',\n",
      "                      'leftWrist',\n",
      "                      'rightWrist',\n",
      "                      'waterDrop'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ReachingTopFeb24\\\\ReachingTop_Sarah95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deterministic': False,\n",
      " 'display_iters': 100,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'D:\\\\anaconda\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ReachingTopFeb24\\\\Documentation_data-ReachingTop_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 8,\n",
      " 'optimizer': 'sgd',\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'D:\\\\DeepLabCut\\\\projects\\\\ReachingTop-Sarah-2020-02-24',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 100,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'D:\\\\DeepLabCut\\\\projects\\\\ReachingTop-Sarah-2020-02-24\\\\dlc-models\\\\iteration-0\\\\ReachingTopFeb24-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running  DeepCut_resnet50_ReachingTopFeb24shuffle1_14900  with # of trainingiterations: 14900\n",
      "INFO:tensorflow:Restoring parameters from D:\\DeepLabCut\\projects\\ReachingTop-Sarah-2020-02-24\\dlc-models\\iteration-0\\ReachingTopFeb24-trainset95shuffle1\\train\\snapshot-14900\n",
      "Analyzing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [00:16,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done and results stored for snapshot:  snapshot-14900\n",
      "Results for 14900  training iterations: 95 1 train error: 6.93 pixels. Test error: 6.5  pixels.\n",
      "With pcutoff of 0.1  train error: 6.93 pixels. Test error: 6.5 pixels\n",
      "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
      "Plotting...\n",
      "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
      "If it generalizes well, choose the best model for prediction and update the config file with the appropriate index for the 'snapshotindex'.\n",
      "Use the function 'analyze_video' to make predictions on new videos.\n",
      "Otherwise consider retraining the network (see DeepLabCut workflow Fig 2)\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.evaluate_network(path_config_file, plotting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7]],\n",
      " 'all_joints_names': ['leftEar',\n",
      "                      'rightEar',\n",
      "                      'leftEye',\n",
      "                      'rightEye',\n",
      "                      'nose',\n",
      "                      'leftWrist',\n",
      "                      'rightWrist',\n",
      "                      'waterDrop'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ReachingTopFeb24\\\\ReachingTop_Sarah95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deterministic': False,\n",
      " 'display_iters': 100,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'D:\\\\anaconda\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_ReachingTopFeb24\\\\Documentation_data-ReachingTop_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 8,\n",
      " 'optimizer': 'sgd',\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'D:\\\\DeepLabCut\\\\projects\\\\ReachingTop-Sarah-2020-02-24',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 100,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'D:\\\\DeepLabCut\\\\projects\\\\ReachingTop-Sarah-2020-02-24\\\\dlc-models\\\\iteration-0\\\\ReachingTopFeb24-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-14900 for model D:\\DeepLabCut\\projects\\ReachingTop-Sarah-2020-02-24\\dlc-models\\iteration-0\\ReachingTopFeb24-trainset95shuffle1\n",
      "num_outputs =  1\n",
      "INFO:tensorflow:Restoring parameters from D:\\DeepLabCut\\projects\\ReachingTop-Sarah-2020-02-24\\dlc-models\\iteration-0\\ReachingTopFeb24-trainset95shuffle1\\train\\snapshot-14900\n",
      "Analyzing all the videos in the directory\n",
      "Starting to analyze %  20200221_WT1_D1_top.avi\n",
      "Loading  20200221_WT1_D1_top.avi\n",
      "Duration of video [s]:  5.68 , recorded with  60.0 fps!\n",
      "Overall # of frames:  341  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "350it [01:14,  5.08it/s]                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "350it [01:16,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in ....\n",
      "Saving csv poses!\n",
      "Starting to analyze %  20200221_WT1_D2_top.avi\n",
      "Loading  20200221_WT1_D2_top.avi\n",
      "Duration of video [s]:  8.33 , recorded with  60.0 fps!\n",
      "Overall # of frames:  500  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "510it [01:42,  5.07it/s]                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "510it [01:43,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in ....\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract any outlier frames!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DeepCut_resnet50_ReachingTopFeb24shuffle1_14900'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videofile_path = [os.path.join(ddrive, 'DeepLabCut', 'projects', 'ReachingTop-Sarah-2020-02-24', 'videos')]\n",
    "deeplabcut.analyze_videos(path_config_file,videofile_path, videotype='.avi', save_as_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isfile(os.sep.join(['D:', 'academy_videos', 'f-cam', 'M18_HoldBite_1561436695_FrontVideo.avi']))\n",
    "#os.path.isfile(\"D:\\academy_videos\\f-cam\\M18_HoldBite_1561436695_FrontVideo.avi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
